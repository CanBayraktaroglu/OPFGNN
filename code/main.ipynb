{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional\n",
    "\n",
    "from helper import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "HOMOGENEOUS MODEL:\n",
    " GNN in gnn.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load the homogeneous model\n",
    "homogeneous_model = load_homogeneous_supervised_model()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating edge index and edge attributes for the grid 1-HV-mixed--0-no_sw ...\n",
      "Reading all of the .csv files from the directory of 1-HV-mixed--0-no_sw ...\n",
      "Processing Training Data for 1-HV-mixed--0-no_sw ...\n",
      "Processing Validation Data for 1-HV-mixed--0-no_sw ...\n",
      "Processing Test Data for 1-HV-mixed--0-no_sw ...\n",
      "Processing complete.\n",
      "Calculating edge index and edge attributes for the grid 1-HV-urban--0-no_sw ...\n",
      "Reading all of the .csv files from the directory of 1-HV-urban--0-no_sw ...\n",
      "Processing Training Data for 1-HV-urban--0-no_sw ...\n",
      "Processing Validation Data for 1-HV-urban--0-no_sw ...\n",
      "Processing Test Data for 1-HV-urban--0-no_sw ...\n",
      "Processing complete.\n",
      "Calculating edge index and edge attributes for the grid 1-MV-comm--0-no_sw ...\n",
      "Reading all of the .csv files from the directory of 1-MV-comm--0-no_sw ...\n",
      "Processing Training Data for 1-MV-comm--0-no_sw ...\n",
      "Processing Validation Data for 1-MV-comm--0-no_sw ...\n",
      "Processing Test Data for 1-MV-comm--0-no_sw ...\n",
      "Processing complete.\n",
      "Calculating edge index and edge attributes for the grid 1-MV-semiurb--0-no_sw ...\n",
      "Reading all of the .csv files from the directory of 1-MV-semiurb--0-no_sw ...\n",
      "Processing Training Data for 1-MV-semiurb--0-no_sw ...\n",
      "Processing Validation Data for 1-MV-semiurb--0-no_sw ...\n",
      "Processing Test Data for 1-MV-semiurb--0-no_sw ...\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "#Read the grid names from directory\n",
    "grid_names = [_ for _ in os.listdir(os.path.dirname(os.path.abspath(\"gnn.ipynb\")) + \"\\\\data\\\\Supervised\\\\\")]\n",
    "\n",
    "# Read the homogeneous Datasets in CSV format and convert them to graph data\n",
    "# Append the graph data to a list\n",
    "graphdata_lst = read_multiple_supervised_datasets(grid_names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Name: 1-HV-mixed--0-no_sw, Len_Train: 85,Len_Val: 10,Len_Test: 5\n",
      "Grid Name: 1-HV-urban--0-no_sw, Len_Train: 85,Len_Val: 10,Len_Test: 5\n",
      "Grid Name: 1-MV-comm--0-no_sw, Len_Train: 85,Len_Val: 10,Len_Test: 5\n",
      "Grid Name: 1-MV-semiurb--0-no_sw, Len_Train: 85,Len_Val: 10,Len_Test: 5\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Initialize the list of test loaders\n",
    "test_loaders_lst = []\n",
    "# Iterate over each graph data\n",
    "\n",
    "for graph_data in graphdata_lst:\n",
    "    grid_name = graph_data.grid_name\n",
    "    ln_train_dataset = len(graph_data.train_data)\n",
    "    ln_val_dataset = len(graph_data.val_data)\n",
    "    ln_test_dataset = len(graph_data.test_data)\n",
    "\n",
    "    # Print the grid name and the lengths of training,validation and test datasets\n",
    "    print (f\"Grid Name: {grid_name}, Len_Train: {ln_train_dataset},Len_Val: {ln_val_dataset},Len_Test: {ln_test_dataset}\")\n",
    "\n",
    "    #Append the test dataset of the network graph to the list\n",
    "    test_loader =  DataLoader(graph_data.test_data, batch_size=1, shuffle=True)\n",
    "    test_loaders_lst.append(test_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0025144025683403017\n",
      "MAE: 0.0015600726124830543\n",
      "MRE: 0.032442216062918305\n"
     ]
    }
   ],
   "source": [
    "def test_homogeneous_model(test_loader_lst, model, loss_fn):\n",
    "    test_rmse_loss = 0.0\n",
    "    test_mae_loss = 0.0\n",
    "    test_mre_loss = 0.0\n",
    "    out = []\n",
    "\n",
    "    # create a criterion to measure the mean absolute error\n",
    "    mae_loss_fn = nn.L1Loss()\n",
    "\n",
    "    # create a criterion to measure the mean relative error (MRE), outputs, targets : Torch.Tensor\n",
    "    mre_loss_fn = lambda outputs, targets: get_mre_loss(outputs, targets)\n",
    "\n",
    "    for i, test_loader in enumerate(test_loader_lst):\n",
    "\n",
    "        # Here, we use enumerate(validation_loader) instead of\n",
    "        # iter(validation_loader) so that we can track the batch\n",
    "        # index and do some intra-epoch reporting\n",
    "        for j, data in enumerate(test_loader):\n",
    "            scaler = StandardScaler()\n",
    "            inputs, targets = data.x, data.y\n",
    "\n",
    "            # Get edge_index and edge_attr from DataLoader\n",
    "            edge_index = test_loader.dataset[j].edge_index\n",
    "            edge_attr = test_loader.dataset[j].edge_attr\n",
    "\n",
    "            # Define Scaler and standardize inputs and targets\n",
    "            targets = torch.tensor(scaler.fit_transform(targets), dtype=torch.float32)\n",
    "            inputs = torch.tensor(scaler.transform(inputs), dtype=torch.float32)\n",
    "\n",
    "            # Make predictions for this batch\n",
    "            outputs = model(inputs, edge_index, edge_attr=edge_attr)\n",
    "\n",
    "            # Compute the loss and its gradients\n",
    "            rmse_loss = torch.sqrt(loss_fn(outputs, targets))\n",
    "\n",
    "            # Compute MAE loss\n",
    "            mae_loss = mae_loss_fn(outputs, targets)\n",
    "\n",
    "            # Compute MRE loss\n",
    "            mre_loss = mre_loss_fn(outputs, targets)\n",
    "\n",
    "            # Gather data and report\n",
    "            test_rmse_loss += rmse_loss.item()\n",
    "            test_mae_loss += mae_loss.item()\n",
    "            test_mre_loss += mre_loss.item()\n",
    "\n",
    "            if j + 1 == len(test_loader.dataset):\n",
    "                output = scaler.inverse_transform(outputs.detach().numpy())\n",
    "                target = scaler.inverse_transform(targets.detach().numpy())\n",
    "                out.append((output, target))\n",
    "\n",
    "    num_samples = len(test_loader_lst) * len(test_loader_lst[0].dataset)\n",
    "    rmse = test_rmse_loss / num_samples\n",
    "    mae = test_mae_loss / num_samples\n",
    "    mre = test_mre_loss / num_samples\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"MRE: {mre}\")\n",
    "    return out\n",
    "\n",
    "outputs_and_targets = test_homogeneous_model(test_loaders_lst, homogeneous_model, nn.MSELoss())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "HETEROGENEOUS MODELS in heterognn.py:\n",
    "    --Node Type-Based Heterogeneous GNN: ACOPFGENERAL\n",
    "    --Edge Type-Based Heterogeneous GNN: ACOPFGNN\n",
    "    --Node Type-Based Heterogeneous GNN with Embedded Constraint Enforcement: ACOPFEmbedder_Bus_Constrained"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "no costs are given - overall generated power is minimized\n",
      "no costs are given - overall generated power is minimized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'SB': tensor([[-0.4302, -1.7190, -1.0855, -3.8420]], grad_fn=<ViewBackward0>), 'PQ': tensor([[ 2.7005e+00, -1.5580e+00, -4.6643e-01, -1.7507e-03],\n",
      "        [-7.8407e-01,  4.2531e-01,  1.2906e+00,  3.1077e+00],\n",
      "        [ 2.3654e+00, -2.1333e+00,  3.5059e-01, -8.4045e-01],\n",
      "        [-1.2202e+00, -4.8966e-01,  9.4935e-01, -1.8552e+00],\n",
      "        [ 2.3693e+00,  1.0654e+00,  2.3733e+00, -9.6047e-01],\n",
      "        [-1.2099e+00,  4.1933e-01,  6.8711e-01,  3.6141e-01],\n",
      "        [ 4.0523e+00, -7.6624e-01,  1.3330e+00,  2.4622e+00],\n",
      "        [-2.2695e+00, -8.2577e-01,  2.5819e+00, -1.4876e+00],\n",
      "        [ 1.9977e-01,  1.3011e+00,  8.1407e-01, -5.4154e-01],\n",
      "        [-1.8558e+00, -3.3946e+00, -6.5611e-01,  1.4513e+00],\n",
      "        [-3.9130e+00, -1.9346e+00, -1.0810e+00, -8.5973e-02],\n",
      "        [-5.2412e-01, -1.5206e+00,  6.9196e-01, -3.9428e+00],\n",
      "        [-1.6743e+00,  1.3425e+00, -2.9726e+00,  7.2980e-01],\n",
      "        [ 5.0029e-02,  2.3143e+00,  2.6966e+00,  1.0052e+00],\n",
      "        [-4.2590e+00,  9.3737e-01, -1.0538e-01, -2.5581e+00],\n",
      "        [ 8.5963e-01,  1.5695e+00, -1.7102e+00,  2.8489e+00]],\n",
      "       grad_fn=<ViewBackward0>), 'PV': tensor([[ 1.2060,  0.8155,  1.1758, -1.3453],\n",
      "        [-1.1848,  1.6796, -3.5541,  3.2266],\n",
      "        [ 0.1608,  0.1126,  0.8993,  4.4713],\n",
      "        [ 1.4370,  1.6687, -2.2864, -0.2742],\n",
      "        [ 2.6533, -2.1152, -3.1336,  2.5802],\n",
      "        [-2.8357, -0.3734,  1.0307, -0.2252],\n",
      "        [ 0.5425, -0.6316,  4.3458, -0.8203],\n",
      "        [ 1.7337,  1.6877,  0.3144, -0.5063],\n",
      "        [-0.9283, -2.9648,  0.1928, -1.8189],\n",
      "        [ 0.1537, -1.4516, -4.1045, -0.9466],\n",
      "        [ 2.0519,  1.6782,  4.3949,  1.5493],\n",
      "        [ 0.8101, -0.5885, -0.0603, -0.6130],\n",
      "        [-1.4374,  2.1563, -0.6156, -1.0077],\n",
      "        [-0.7020,  2.7501,  0.8823, -0.3515],\n",
      "        [ 1.7089, -2.8856,  0.9047, -0.5745],\n",
      "        [ 0.1847,  1.5735,  1.9761,  2.3518],\n",
      "        [ 0.4241, -4.0672,  0.4736, -1.6249],\n",
      "        [-0.6145,  0.1935, -2.1744,  2.7138],\n",
      "        [-1.7827,  0.3983,  1.0246, -2.4966],\n",
      "        [-3.4186,  0.3301, -4.0419, -2.1951],\n",
      "        [-1.0622, -1.7441, -1.5799, -2.5160],\n",
      "        [ 0.4714,  4.4079,  0.7399, -1.4500],\n",
      "        [ 2.0639,  1.6556, -2.1840,  1.9089],\n",
      "        [-1.5184,  1.6615,  1.0112,  3.0265],\n",
      "        [-0.2936,  4.1072, -0.1075, -0.8081],\n",
      "        [ 2.8954,  2.2419,  1.1757, -0.5773],\n",
      "        [-1.6190, -2.1453,  1.0218, -1.5783],\n",
      "        [ 0.0770, -0.4260,  1.4820,  0.9669],\n",
      "        [-1.3959, -1.3955, -0.3327, -0.6731],\n",
      "        [ 1.9990,  1.5679, -1.0699, -0.9473],\n",
      "        [ 1.9369,  0.6099,  1.5323, -1.4470],\n",
      "        [-2.5409,  3.7285, -0.5570,  2.6660],\n",
      "        [-1.2251, -2.0287,  0.6098,  1.6722],\n",
      "        [-0.1743, -2.8575, -0.6831, -1.6182],\n",
      "        [-1.2787,  0.9493, -1.1060,  1.3989],\n",
      "        [ 0.0893,  1.4826, -1.7911,  2.1484],\n",
      "        [ 2.8466,  3.3801,  1.3038,  4.9777],\n",
      "        [ 0.9802, -1.6185,  2.0093,  1.1565],\n",
      "        [ 0.4196, -4.4164,  1.5333, -2.3435],\n",
      "        [-0.6758, -1.2100, -3.2735, -3.0187],\n",
      "        [-0.3075,  2.2653,  0.4690, -2.6990],\n",
      "        [-0.1153, -1.5972,  1.6609,  1.5602]], grad_fn=<ViewBackward0>), 'NB': tensor([[-1.7570, -0.2737,  2.9126, -3.1106],\n",
      "        [ 1.9633, -1.9032,  1.8496, -3.8860],\n",
      "        [ 1.9827,  3.4713, -0.0409, -2.6403],\n",
      "        [ 3.0653,  2.4607, -1.0002, -0.6298],\n",
      "        [ 6.0593,  1.1537,  6.3757,  2.9857]], grad_fn=<ViewBackward0>)})\n"
     ]
    }
   ],
   "source": [
    "# Load the node-type based heterogeneous GNN\n",
    "heterogeneous_model = load_ACOPFGeneral_model('1-HV-mixed--0-no_sw', \"hetero_model_bus_final.pt\",16,1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Load Inputs\n",
    "inputs = load_unsupervised_inputs('1-HV-mixed--0-no_sw')\n",
    "n = len(inputs)\n",
    "test_inputs = inputs[int(n*0.95):]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<ACOPFData.ACOPFInput at 0x2afb9ef9f60>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.006351334974169731\n",
      "MAE: 0.0020139727275818586\n",
      "MRE: 0.04707365483045578\n"
     ]
    }
   ],
   "source": [
    "def test_heterogeneous_model(model, test_inputs):\n",
    "    test_rmse_loss = 0.0\n",
    "    test_mae_loss = 0.0\n",
    "    test_mre_loss = 0.0\n",
    "\n",
    "    for j, ACOPFinput in enumerate(test_inputs):\n",
    "\n",
    "        # Store the attributes in variables to be used later on\n",
    "        x_dict = ACOPFinput.x_dict\n",
    "        constraint_dict = ACOPFinput.constraint_dict\n",
    "        edge_idx_dict = ACOPFinput.edge_idx_dict\n",
    "        edge_attr_dict = ACOPFinput.edge_attr_dict\n",
    "        bus_idx_neighbors_dict = ACOPFinput.bus_idx_neighbors_dict\n",
    "        net = ACOPFinput.net\n",
    "        scaler = ACOPFinput.scaler\n",
    "        res_dict = ACOPFinput.res_bus\n",
    "\n",
    "        out_dict = model(x_dict, bus_idx_neighbors_dict, edge_idx_dict, edge_attr_dict)\n",
    "\n",
    "        target, output = [],[]\n",
    "        for node_type in out_dict:\n",
    "            output.extend(out_dict[node_type])\n",
    "            target.extend(res_dict[node_type])\n",
    "\n",
    "        x = torch.stack(output)\n",
    "        y = torch.stack(target)\n",
    "\n",
    "        rmseloss = torch.sqrt(torch.nn.functional.mse_loss(x, y))\n",
    "        maeloss = torch.nn.functional.l1_loss(x,y)\n",
    "        mreloss = get_mre_loss(x, y)\n",
    "\n",
    "        # Add the losses\n",
    "        test_rmse_loss += rmseloss\n",
    "        test_mae_loss += maeloss\n",
    "        test_mre_loss += mreloss\n",
    "\n",
    "    n = len(test_inputs)\n",
    "    RMSE = test_rmse_loss / n\n",
    "    MAE = test_mae_loss / n\n",
    "    MRE = test_mre_loss / n\n",
    "\n",
    "    print(f\"RMSE: {RMSE}\")\n",
    "    print(f\"MAE: {MAE}\")\n",
    "    print(f\"MRE: {MRE}\")\n",
    "\n",
    "\n",
    "test_heterogeneous_model(heterogeneous_model, test_inputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
