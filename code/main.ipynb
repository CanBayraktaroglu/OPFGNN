{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional\n",
    "\n",
    "from helper import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "HOMOGENEOUS MODEL:\n",
    " GNN in gnn.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Load the homogeneous model\n",
    "homogeneous_model = load_homogeneous_supervised_model()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating edge index and edge attributes for the grid 1-HV-mixed--0-no_sw ...\n",
      "Reading all of the .csv files from the directory of 1-HV-mixed--0-no_sw ...\n",
      "Processing Training Data for 1-HV-mixed--0-no_sw ...\n",
      "Processing Validation Data for 1-HV-mixed--0-no_sw ...\n",
      "Processing Test Data for 1-HV-mixed--0-no_sw ...\n",
      "Processing complete.\n",
      "Calculating edge index and edge attributes for the grid 1-HV-urban--0-no_sw ...\n",
      "Reading all of the .csv files from the directory of 1-HV-urban--0-no_sw ...\n",
      "Processing Training Data for 1-HV-urban--0-no_sw ...\n",
      "Processing Validation Data for 1-HV-urban--0-no_sw ...\n",
      "Processing Test Data for 1-HV-urban--0-no_sw ...\n",
      "Processing complete.\n",
      "Calculating edge index and edge attributes for the grid 1-MV-comm--0-no_sw ...\n",
      "Reading all of the .csv files from the directory of 1-MV-comm--0-no_sw ...\n",
      "Processing Training Data for 1-MV-comm--0-no_sw ...\n",
      "Processing Validation Data for 1-MV-comm--0-no_sw ...\n",
      "Processing Test Data for 1-MV-comm--0-no_sw ...\n",
      "Processing complete.\n",
      "Calculating edge index and edge attributes for the grid 1-MV-semiurb--0-no_sw ...\n",
      "Reading all of the .csv files from the directory of 1-MV-semiurb--0-no_sw ...\n",
      "Processing Training Data for 1-MV-semiurb--0-no_sw ...\n",
      "Processing Validation Data for 1-MV-semiurb--0-no_sw ...\n",
      "Processing Test Data for 1-MV-semiurb--0-no_sw ...\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "#Read the grid names from directory\n",
    "grid_names = [_ for _ in os.listdir(os.path.dirname(os.path.abspath(\"gnn.ipynb\")) + \"\\\\data\\\\Supervised\\\\\")]\n",
    "\n",
    "# Read the homogeneous Datasets in CSV format and convert them to graph data\n",
    "# Append the graph data to a list\n",
    "graphdata_lst = read_multiple_supervised_datasets(grid_names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Name: 1-HV-mixed--0-no_sw, Len_Train: 85,Len_Val: 10,Len_Test: 5\n",
      "Grid Name: 1-HV-urban--0-no_sw, Len_Train: 85,Len_Val: 10,Len_Test: 5\n",
      "Grid Name: 1-MV-comm--0-no_sw, Len_Train: 85,Len_Val: 10,Len_Test: 5\n",
      "Grid Name: 1-MV-semiurb--0-no_sw, Len_Train: 85,Len_Val: 10,Len_Test: 5\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Initialize the list of test loaders\n",
    "test_loaders_lst = []\n",
    "# Iterate over each graph data\n",
    "\n",
    "for graph_data in graphdata_lst:\n",
    "    grid_name = graph_data.grid_name\n",
    "    ln_train_dataset = len(graph_data.train_data)\n",
    "    ln_val_dataset = len(graph_data.val_data)\n",
    "    ln_test_dataset = len(graph_data.test_data)\n",
    "\n",
    "    # Print the grid name and the lengths of training,validation and test datasets\n",
    "    print (f\"Grid Name: {grid_name}, Len_Train: {ln_train_dataset},Len_Val: {ln_val_dataset},Len_Test: {ln_test_dataset}\")\n",
    "\n",
    "    #Append the test dataset of the network graph to the list\n",
    "    test_loader =  DataLoader(graph_data.test_data, batch_size=1, shuffle=True)\n",
    "    test_loaders_lst.append(test_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.002404558245325461\n",
      "MAE: 0.0015261667082086205\n",
      "MRE: 0.020806053886190057\n"
     ]
    }
   ],
   "source": [
    "def test_homogeneous_model(test_loader_lst, model, loss_fn):\n",
    "    test_rmse_loss = 0.0\n",
    "    test_mae_loss = 0.0\n",
    "    test_mre_loss = 0.0\n",
    "    out = []\n",
    "\n",
    "    # create a criterion to measure the mean absolute error\n",
    "    mae_loss_fn = nn.L1Loss()\n",
    "\n",
    "    # create a criterion to measure the mean relative error (MRE), outputs, targets : Torch.Tensor\n",
    "    mre_loss_fn = lambda outputs, targets: get_mre_loss(outputs, targets)\n",
    "\n",
    "    for i, test_loader in enumerate(test_loader_lst):\n",
    "\n",
    "        # Here, we use enumerate(validation_loader) instead of\n",
    "        # iter(validation_loader) so that we can track the batch\n",
    "        # index and do some intra-epoch reporting\n",
    "        for j, data in enumerate(test_loader):\n",
    "            scaler = StandardScaler()\n",
    "            inputs, targets = data.x, data.y\n",
    "\n",
    "            # Get edge_index and edge_attr from DataLoader\n",
    "            edge_index = test_loader.dataset[j].edge_index\n",
    "            edge_attr = test_loader.dataset[j].edge_attr\n",
    "\n",
    "            # Define Scaler and standardize inputs and targets\n",
    "            targets = torch.tensor(scaler.fit_transform(targets), dtype=torch.float32)\n",
    "            inputs = torch.tensor(scaler.transform(inputs), dtype=torch.float32)\n",
    "\n",
    "            # Make predictions for this batch\n",
    "            outputs = model(inputs, edge_index, edge_attr=edge_attr)\n",
    "\n",
    "            # Compute the loss and its gradients\n",
    "            rmse_loss = torch.sqrt(loss_fn(outputs, targets))\n",
    "\n",
    "            # Compute MAE loss\n",
    "            mae_loss = mae_loss_fn(outputs, targets)\n",
    "\n",
    "            # Compute MRE loss\n",
    "            mre_loss = mre_loss_fn(outputs, targets)\n",
    "\n",
    "            # Gather data and report\n",
    "            test_rmse_loss += rmse_loss.item()\n",
    "            test_mae_loss += mae_loss.item()\n",
    "            test_mre_loss += mre_loss.item()\n",
    "\n",
    "            if j + 1 == len(test_loader.dataset):\n",
    "                output = scaler.inverse_transform(outputs.detach().numpy())\n",
    "                target = scaler.inverse_transform(targets.detach().numpy())\n",
    "                out.append((output, target))\n",
    "\n",
    "    num_samples = len(test_loader_lst) * len(test_loader_lst[0].dataset)\n",
    "    rmse = test_rmse_loss / num_samples\n",
    "    mae = test_mae_loss / num_samples\n",
    "    mre = test_mre_loss / num_samples\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"MRE: {mre}\")\n",
    "    return out\n",
    "\n",
    "outputs_and_targets = test_homogeneous_model(test_loaders_lst, homogeneous_model, nn.MSELoss())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "HETEROGENEOUS MODELS in heterognn.py:\n",
    "    --Node Type-Based Heterogeneous GNN: ACOPFGENERAL\n",
    "    --Edge Type-Based Heterogeneous GNN: ACOPFGNN\n",
    "    --Node Type-Based Heterogeneous GNN with Embedded Constraint Enforcement: ACOPFEmbedder_Bus_Constrained"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "no costs are given - overall generated power is minimized\n",
      "no costs are given - overall generated power is minimized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'SB': tensor([[4.3778, 4.3980, 1.2443, 0.1817]], grad_fn=<ViewBackward0>), 'PQ': tensor([[ 0.6957, -0.2536, -2.1259,  0.2346],\n",
      "        [-0.5310,  2.2922, -0.7527,  2.8672],\n",
      "        [ 0.1181, -2.6972,  3.4727, -2.5558],\n",
      "        [ 2.1422, -2.7961,  3.6309,  5.2956],\n",
      "        [-0.5516, -1.4706, -0.3314, -0.6005],\n",
      "        [-1.1938, -4.3016, -1.9444, -1.3011],\n",
      "        [ 2.6649,  1.7119,  2.8390,  0.4738],\n",
      "        [-1.3251,  1.4579, -2.1068,  1.9568],\n",
      "        [ 1.4279, -0.0398, -3.1550,  1.8049],\n",
      "        [-1.3081,  3.9212,  0.4466, -2.7417],\n",
      "        [ 1.4596,  0.5066, -0.2251,  0.1342],\n",
      "        [-0.9125, -2.2541, -0.7617, -3.4120],\n",
      "        [ 0.9590,  2.5350,  1.3388, -1.1577],\n",
      "        [-2.8009,  0.6519,  3.9448,  0.6603],\n",
      "        [ 2.5201,  0.3159, -2.3347,  1.7825],\n",
      "        [-0.2740,  2.0715, -0.2225,  0.7886]], grad_fn=<ViewBackward0>), 'PV': tensor([[ 0.4633,  0.9339, -0.3001,  0.1313],\n",
      "        [-2.0569, -1.0954, -0.3790,  1.7793],\n",
      "        [ 1.9897,  1.1761,  0.4006, -2.1919],\n",
      "        [ 2.4957,  2.3918, -0.5817, -0.9024],\n",
      "        [ 3.4775, -1.4989,  2.1389, -0.1991],\n",
      "        [ 1.7103,  0.8973,  3.6305, -0.0712],\n",
      "        [ 2.3224, -2.5672, -0.3418, -1.0059],\n",
      "        [-0.6820, -0.8447, -1.8662, -1.7840],\n",
      "        [ 4.3369, -0.8623, -0.4132,  0.8316],\n",
      "        [ 0.4820, -2.0415,  2.2359, -0.0876],\n",
      "        [ 1.3571,  2.8421, -0.2011, -0.8541],\n",
      "        [-0.7366, -2.4171, -1.7010,  1.6251],\n",
      "        [ 2.1876, -1.5346,  0.5147, -0.9229],\n",
      "        [-1.0844,  2.4551, -0.8273,  0.4089],\n",
      "        [ 2.0616,  2.5977, -1.4181, -1.7420],\n",
      "        [-0.0779,  2.0762,  0.1325,  1.7360],\n",
      "        [ 0.9212,  0.4592, -0.2694, -3.0724],\n",
      "        [ 5.9739, -1.2581, -0.4551,  0.9843],\n",
      "        [ 1.1759, -1.3216,  0.2800,  1.1181],\n",
      "        [ 0.4718, -0.5594,  2.1478, -0.4584],\n",
      "        [ 1.1875,  1.4678,  0.8396,  0.5087],\n",
      "        [ 0.4241, -2.9619, -0.1078,  0.6404],\n",
      "        [-1.9799,  1.0739, -2.2912,  1.5082],\n",
      "        [ 0.2267,  0.8078,  1.1037, -1.2409],\n",
      "        [-1.1419,  1.1188,  0.9649, -1.6314],\n",
      "        [ 1.4914, -2.1903, -1.9934,  0.7649],\n",
      "        [ 1.4075, -0.4708,  0.5094,  2.4133],\n",
      "        [-0.4360, -2.0697, -1.0311,  1.0518],\n",
      "        [ 0.7259, -2.9937, -2.3423,  1.1789],\n",
      "        [-1.7686, -3.3156,  0.4253,  0.2223],\n",
      "        [-0.9263, -2.5859,  0.1987,  3.5727],\n",
      "        [-0.2994, -4.5529,  1.0115, -4.2955],\n",
      "        [ 0.0676, -2.8209,  0.3156,  0.6876],\n",
      "        [-0.0278,  1.0947,  1.7690,  1.1144],\n",
      "        [ 0.8619, -1.9714, -1.5140, -0.5835],\n",
      "        [-0.9039, -2.1140, -3.7052, -2.6633],\n",
      "        [ 1.1101, -1.6633,  3.1031, -2.7894],\n",
      "        [ 0.3278, -0.2856,  0.3409,  1.4663],\n",
      "        [-4.1054,  1.5449,  0.4850,  1.0205],\n",
      "        [-3.2699,  1.2332,  2.0467, -2.3441],\n",
      "        [-0.8924,  0.1513,  0.0996,  1.3197],\n",
      "        [-0.8461,  3.0078, -0.4863, -2.5836]], grad_fn=<ViewBackward0>), 'NB': tensor([[ 1.9132, -3.4232,  2.9161, -2.1958],\n",
      "        [-0.1163, -3.8910,  3.8232,  0.3822],\n",
      "        [-4.6729,  2.4166, -1.9135,  0.2752],\n",
      "        [ 2.1493, -1.5459, -0.4861,  0.8739],\n",
      "        [ 2.3808,  4.2772,  4.7981, -0.1456]], grad_fn=<ViewBackward0>)})\n"
     ]
    }
   ],
   "source": [
    "# Load the node-type based heterogeneous GNN\n",
    "heterogeneous_model = load_ACOPFGeneral_model('1-HV-mixed--0-no_sw', \"hetero_model_bus_final.pt\",16,1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def load_test_data():\n",
    "    path = \"../code/data/Heterogeneous/TestData\"\n",
    "    with open(os.path.join(path, 'testdata.pkl'), 'rb') as f:\n",
    "        test_data = pickle.load(f)\n",
    "\n",
    "    print(\"Test Data Loaded.\")\n",
    "    return  test_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load Test Data\n",
    "test_inputs = load_test_data()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<ACOPFData.ACOPFInput at 0x274963086a0>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.006351334974169731\n",
      "MAE: 0.0020139727275818586\n",
      "MRE: 0.04707365483045578\n"
     ]
    }
   ],
   "source": [
    "def test_heterogeneous_model(model, test_inputs):\n",
    "    test_rmse_loss = 0.0\n",
    "    test_mae_loss = 0.0\n",
    "    test_mre_loss = 0.0\n",
    "\n",
    "    for j, ACOPFinput in enumerate(test_inputs):\n",
    "\n",
    "        # Store the attributes in variables to be used later on\n",
    "        x_dict = ACOPFinput.x_dict\n",
    "        constraint_dict = ACOPFinput.constraint_dict\n",
    "        edge_idx_dict = ACOPFinput.edge_idx_dict\n",
    "        edge_attr_dict = ACOPFinput.edge_attr_dict\n",
    "        bus_idx_neighbors_dict = ACOPFinput.bus_idx_neighbors_dict\n",
    "        net = ACOPFinput.net\n",
    "        scaler = ACOPFinput.scaler\n",
    "        res_dict = ACOPFinput.res_bus\n",
    "\n",
    "        out_dict = model(x_dict, bus_idx_neighbors_dict, edge_idx_dict, edge_attr_dict)\n",
    "\n",
    "        target, output = [],[]\n",
    "        for node_type in out_dict:\n",
    "            output.extend(out_dict[node_type])\n",
    "            target.extend(res_dict[node_type])\n",
    "\n",
    "        x = torch.stack(output)\n",
    "        y = torch.stack(target)\n",
    "\n",
    "        rmseloss = torch.sqrt(torch.nn.functional.mse_loss(x, y))\n",
    "        maeloss = torch.nn.functional.l1_loss(x,y)\n",
    "        mreloss = get_mre_loss(x, y)\n",
    "\n",
    "        # Add the losses\n",
    "        test_rmse_loss += rmseloss\n",
    "        test_mae_loss += maeloss\n",
    "        test_mre_loss += mreloss\n",
    "\n",
    "    n = len(test_inputs)\n",
    "    RMSE = test_rmse_loss / n\n",
    "    MAE = test_mae_loss / n\n",
    "    MRE = test_mre_loss / n\n",
    "\n",
    "    print(f\"RMSE: {RMSE}\")\n",
    "    print(f\"MAE: {MAE}\")\n",
    "    print(f\"MRE: {MRE}\")\n",
    "\n",
    "\n",
    "test_heterogeneous_model(heterogeneous_model, test_inputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
